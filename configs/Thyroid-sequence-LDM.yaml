data_name: "TUSC"
pretrained_2d_model_path: "your_LDM_dir"
output_dir: "your_output_dir"
caption_column: null
video_column: "file_name"
image_condition: True
motion_condition: True
image_encode: "MedSAM"

train_data:
  data_path: "TUSC/TUSC_video"
  width: 256
  height: 256
  keep_all_cond_prob: 0.1
  drop_all_cond_prob: 0.1
  drop_each_cond_prob: [0.5, 0.5] # drop for image prior and motion field

validation_data:
  labels:
    - "TR2-3"
    - "TR4"
    - "TR4"
    - "TR2-3"
    - "TR5"
    - "TR5"

  videos:
    - "TUSC/TUSC_video/Nodule43_f1.avi"
    - "TUSC/TUSC_video/Nodule206_f18.avi"
    - "TUSC/TUSC_video/Nodule106_f1.avi"
    - "TUSC/TUSC_video/Nodule210_f11.avi"
    - "TUSC/TUSC_video/Nodule163_f38.avi" 
    - "TUSC/TUSC_video/Nodule169_f1.avi"

  video_length: 8
  width: 256
  height: 256
  num_inference_steps: 200
  guidance_scale: 7.5

learning_rate: 1e-4
lr_scheduler: "cosine"
lr_warmup_steps: 500
train_batch_size: 8
num_workers: 8
num_train_epochs: 200
checkpointing_steps: xxx # set on your own
validation_steps: xxx    # set on your own
trainable_modules:
  - "attn1"
  - "motion_encoder"
  - "insert_unit" 
  - "multi_modal_attn.attn2.to_q"
  - "multi_modal_attn.attn_condImage.to_q"
  - "norm_temp"
  - "attn_temp"

seed: 3407
use_8bit_adam: False
gradient_accumulation_steps: 1
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: False
